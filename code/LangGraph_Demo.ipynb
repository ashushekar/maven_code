{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39bbaed2",
   "metadata": {},
   "source": [
    "## LangGraph Introduction and Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b6f264-addf-4a8e-a742-0d642a8b3b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "print(os.environ['OPENAI_API_KEY'][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8f0e64",
   "metadata": {},
   "source": [
    "## Simple non-AI graph example\n",
    "Generate some random values, and sum them up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c2ad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "values = [random.randint(0, 10) for _ in range(10)]\n",
    "print(f\"Sum of values: {sum(values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bdfe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the state of the graph:\n",
    "from typing import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    num_values: int\n",
    "    generated_values: list[int]\n",
    "    result: int | None = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674d9e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Define the nodes in the graph:\n",
    "def generate_values(state: State):\n",
    "    values = [random.randint(0, 10) for _ in range(state[\"num_values\"])]\n",
    "    return {\"generated_values\": values}\n",
    "\n",
    "def add(state: State):\n",
    "    result = sum(state[\"generated_values\"])\n",
    "    return {\"result\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7561b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the graph:\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph import START, END\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"generate_values\", generate_values)\n",
    "graph_builder.add_node(\"add\", add)\n",
    "\n",
    "graph_builder.add_edge(START, \"generate_values\")\n",
    "graph_builder.add_edge(\"generate_values\", \"add\")\n",
    "graph_builder.add_edge(\"add\", END)\n",
    "\n",
    "# Now graph is also a 'Runnable'\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0243654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a44f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({\"num_values\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226ab8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12ad2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "await graph.ainvoke({\"num_values\": 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9605a434",
   "metadata": {},
   "source": [
    "## Conditional Edge example in LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792f7ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalEdgeState(TypedDict):\n",
    "    num_values: int\n",
    "    generated_values: list[int]\n",
    "    total: int\n",
    "    # Prints happy if the total is even, sad if the total is odd\n",
    "    final_message: str\n",
    "\n",
    "def generate_values(state: ConditionalEdgeState):\n",
    "    generated_values = [random.randint(0, 10) for _ in range(state[\"num_values\"])]\n",
    "    return {\"generated_values\": generated_values}\n",
    "\n",
    "def add(state: ConditionalEdgeState):\n",
    "    total = sum(state[\"generated_values\"])\n",
    "    return {\"total\": total}\n",
    "\n",
    "def check_total(state: ConditionalEdgeState):\n",
    "    if state[\"total\"] % 2 == 0:\n",
    "        return \"happy_message\"\n",
    "    else:\n",
    "        return \"sad_message\"\n",
    "    \n",
    "def happy_message(state: ConditionalEdgeState):\n",
    "    return {\"final_message\": \"happy\"}\n",
    "\n",
    "def sad_message(state: ConditionalEdgeState):\n",
    "    return {\"final_message\": \"sad\"}\n",
    "\n",
    "graph_builder = StateGraph(ConditionalEdgeState)\n",
    "\n",
    "graph_builder.add_node(\"generate_values\", generate_values)\n",
    "graph_builder.add_node(\"add\", add)\n",
    "graph_builder.add_node(\"happy_message\", happy_message)\n",
    "graph_builder.add_node(\"sad_message\", sad_message)\n",
    "\n",
    "graph_builder.add_edge(START, \"generate_values\")\n",
    "graph_builder.add_edge(\"generate_values\", \"add\")\n",
    "# THIS is the place where the condition is evaluated\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"add\",\n",
    "    check_total,\n",
    "    {\n",
    "        \"happy_message\": \"happy_message\",\n",
    "        \"sad_message\": \"sad_message\",\n",
    "    },\n",
    ")\n",
    "graph_builder.add_edge(\"happy_message\", END)\n",
    "graph_builder.add_edge(\"sad_message\", END)\n",
    "\n",
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2bd4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the graph\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28c2629",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({\"num_values\": 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b4a977",
   "metadata": {},
   "source": [
    "## Using LangChain Components in LangGraph\n",
    "A simple sentiment analyzer that branches to happy or sad responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87fd968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LangChain components\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Initialize model and parser (can be used in LangGraph nodes!)\n",
    "# llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "llm = init_chat_model(\"gpt-5-mini\", model_provider=\"openai\", reasoning_effort=\"minimal\")\n",
    "parser = StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2552801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define state\n",
    "class SentimentState(TypedDict):\n",
    "    sentence: str\n",
    "    sentiment: str\n",
    "    message: str\n",
    "\n",
    "# Node: Analyze sentiment\n",
    "def analyze_sentiment(state: SentimentState):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Analyze sentiment. Reply with ONLY 'happy' or 'sad'.\"),\n",
    "        (\"user\", \"{sentence}\")\n",
    "    ])\n",
    "    chain = prompt | llm | parser\n",
    "    sentiment = chain.invoke({\"sentence\": state[\"sentence\"]}).strip().lower()\n",
    "    return {\"sentiment\": sentiment}\n",
    "\n",
    "# Node: Generate happy message\n",
    "def happy_response(state: SentimentState):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Generate a cheerful, uplifting message in 1 sentence.\"),\n",
    "        (\"user\", \"The person said: {sentence}\")\n",
    "    ])\n",
    "    chain = prompt | llm | parser\n",
    "    message = chain.invoke({\"sentence\": state[\"sentence\"]})\n",
    "    return {\"message\": message}\n",
    "\n",
    "# Node: Generate sad message\n",
    "def sad_response(state: SentimentState):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"Generate a comforting message in 1 sentence that says it's alright.\"),\n",
    "        (\"user\", \"The person said: {sentence}\")\n",
    "    ])\n",
    "    chain = prompt | llm | parser\n",
    "    message = chain.invoke({\"sentence\": state[\"sentence\"]})\n",
    "    return {\"message\": message}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd4fb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Routing function\n",
    "def route_sentiment(state: SentimentState):\n",
    "    if \"happy\" in state[\"sentiment\"]:\n",
    "        return \"happy\"\n",
    "    else:\n",
    "        return \"sad\"\n",
    "\n",
    "# Build the graph\n",
    "builder = StateGraph(SentimentState)\n",
    "builder.add_node(\"analyze_sentiment\", analyze_sentiment)\n",
    "builder.add_node(\"happy\", happy_response)\n",
    "builder.add_node(\"sad\", sad_response)\n",
    "\n",
    "builder.add_edge(START, \"analyze_sentiment\")\n",
    "builder.add_conditional_edges(\"analyze_sentiment\", route_sentiment, {\"happy\": \"happy\", \"sad\": \"sad\"})\n",
    "builder.add_edge(\"happy\", END)\n",
    "builder.add_edge(\"sad\", END)\n",
    "\n",
    "sentiment_graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f523dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graph\n",
    "display(Image(sentiment_graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a795a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Happy sentence\n",
    "result = sentiment_graph.invoke({\"sentence\": \"I got the job! I'm so excited!\"})\n",
    "print(f\"Sentiment: {result['sentiment']}\")\n",
    "print(f\"Message: {result['message']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffc5c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Sad sentence\n",
    "result = sentiment_graph.invoke({\"sentence\": \"I failed my exam and feel terrible.\"})\n",
    "print(f\"Sentiment: {result['sentiment']}\")\n",
    "print(f\"Message: {result['message']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f898cd",
   "metadata": {},
   "source": [
    "## Why LangGraph then where I can do everything in LangChain?\n",
    "- THE central framework from LangChain company.\n",
    "- Less opinionated, more flexibility. Can still use LangChain within the nodes of a graph.\n",
    "- Contains many primitives for building AI agents over the next few weeks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
